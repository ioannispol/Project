{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "humanitarian-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Project Image dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        #image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 2]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(\n",
    "    csv_file='../src/data/raw_labes.csv', \n",
    "    root_dir='../src/data/raw', \n",
    "    transform=transforms.ToTensor()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_file='../dataset/set_dataset/train_labes.csv'\n",
    "train_root_dir='../dataset/set_dataset/train/'\n",
    "\n",
    "annotations = pd.read_csv(train_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(root_dir, annotations.iloc[0, 0])\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread(img_path)\n",
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = torch.tensor(int(annotations.iloc[0, 2]))\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize([224,224]),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = transform_data(image)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(img_path)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../dataset/set_dataset/train'\n",
    "train_labels = '../dataset/set_dataset/train_labes.csv'\n",
    "val_path = '../dataset/set_dataset/val'\n",
    "val_labels = '../dataset/set_dataset/val_labes.csv'\n",
    "test_path = '../dataset/set_dataset/test'\n",
    "test_labels = '../dataset/set_dataset/test_labes.csv'\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 5\n",
    "learning_rate = 1e-3\n",
    "batch_size = 6\n",
    "num_epochs = 10\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.Resize([224,224]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        ])\n",
    "\n",
    "test_val_transform = transforms.Compose([\n",
    "        transforms.Resize([224,224]),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        ])\n",
    "\n",
    "train_dataset = ImageDataset(\n",
    "    csv_file=train_labels, \n",
    "    root_dir=train_path, \n",
    "    transform=train_transform\n",
    "    )\n",
    "val_dataset = ImageDataset(\n",
    "    csv_file=val_labels, \n",
    "    root_dir=val_path, \n",
    "    transform=test_val_transform\n",
    "    ) \n",
    "\n",
    "test_dataset = ImageDataset(\n",
    "    csv_file=test_labels, \n",
    "    root_dir=test_path, \n",
    "    transform=test_val_transform\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(train_dataset) + len(val_dataset) + len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mature-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_input_dims():\n",
    "        batch_data = torch.zeros((1, 3, 224, 224))\n",
    "        batch_data = conv1(batch_data)\n",
    "        batch_data = pool1(batch_data)\n",
    "        batch_data = conv2(batch_data)\n",
    "        batch_data = conv3(batch_data)\n",
    "        batch_data = pool2(batch_data)\n",
    "        batch_data = conv4(batch_data)\n",
    "        batch_data = pool3(batch_data)\n",
    "\n",
    "        return int(np.prod(batch_data.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "conv1 = nn.Conv2d(3, 64, 5)\n",
    "pool1 = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(64, 128, 5)\n",
    "conv3 = nn.Conv2d(128, 64, 5)\n",
    "pool2 = nn.MaxPool2d(2, 2)\n",
    "conv4 = nn.Conv2d(64, 64, 5)\n",
    "pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "input_dims = calc_input_dims()\n",
    "\n",
    "fc1 = nn.Linear(input_dims, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caroline-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        self.conv3 = nn.Conv2d(128, 64, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 5)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        #input_dims = self.calc_input_dims()\n",
    "\n",
    "        self.fc1 = nn.Linear(64*23*23, self.num_classes)\n",
    "\n",
    "    # Function to calculate the input dimension to Linear layer\n",
    "    # TODO: Implement calculation depending on the network structure\n",
    "#     def calc_input_dims(self):\n",
    "#         batch_data = torch.zeros((1, 3, 224, 224))\n",
    "#         batch_data = self.conv1(batch_data)\n",
    "#         batch_data = self.pool1(batch_data)\n",
    "#         batch_data = self.conv2(batch_data)\n",
    "#         batch_data = self.conv3(batch_data)\n",
    "#         batch_data = self.pool2(batch_data)\n",
    "#         batch_data = self.conv4(batch_data)\n",
    "#         batch_data = self.pool3(batch_data)\n",
    "\n",
    "#         return int(np.prod(batch_data.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 64 * 23 *23)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooperative-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=33856, out_features=6, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 220, 220]           4,864\n",
      "         MaxPool2d-2         [-1, 64, 110, 110]               0\n",
      "            Conv2d-3        [-1, 128, 106, 106]         204,928\n",
      "            Conv2d-4         [-1, 64, 102, 102]         204,864\n",
      "         MaxPool2d-5           [-1, 64, 51, 51]               0\n",
      "            Conv2d-6           [-1, 64, 47, 47]         102,464\n",
      "         MaxPool2d-7           [-1, 64, 23, 23]               0\n",
      "            Linear-8                    [-1, 6]         203,142\n",
      "================================================================\n",
      "Total params: 720,262\n",
      "Trainable params: 720,262\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 48.20\n",
      "Params size (MB): 2.75\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "print(net)\n",
    "summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "passive-skiing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=5, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 220, 220]             456\n",
      "         MaxPool2d-2          [-1, 6, 110, 110]               0\n",
      "            Conv2d-3         [-1, 16, 106, 106]           2,416\n",
      "         MaxPool2d-4           [-1, 16, 53, 53]               0\n",
      "            Linear-5                  [-1, 120]       5,393,400\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                    [-1, 5]             425\n",
      "================================================================\n",
      "Total params: 5,406,861\n",
      "Trainable params: 5,406,861\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 4.49\n",
      "Params size (MB): 20.63\n",
      "Estimated Total Size (MB): 25.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 16 * 53 * 53)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)\n",
    "summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personal-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data paths\n",
    "train_path = '../dataset/set_dataset/train'\n",
    "train_labels = '../dataset/set_dataset/train_labes.csv'\n",
    "val_path = '../dataset/set_dataset/val'\n",
    "val_labels = '../dataset/set_dataset/val_labes.csv'\n",
    "test_path = '../dataset/set_dataset/test'\n",
    "test_labels = '../dataset/set_dataset/test_labes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gross-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = [0.5, 0.5, 0.5]\n",
    "std_val = [0.5, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "requested-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_val, std_val),\n",
    "])\n",
    "\n",
    "test_val_transforms = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_val, std_val),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "portuguese-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDataset(train_labels, train_path, train_transforms)\n",
    "val_data = ImageDataset(val_labels, val_path, test_val_transforms)\n",
    "test_data = ImageDataset(test_labels, test_path, test_val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "human-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=6, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_data, batch_size=6, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=6, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ancient-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_data)\n",
    "val_size = len(val_data)\n",
    "test_size = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "criminal-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 1519\n",
      "Validation data size: 474\n",
      "Test data size: 379\n",
      "Total data size: 2372\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data size: {train_size}\\nValidation data size: {val_size}\\n\\\n",
    "Test data size: {test_size}\\nTotal data size: {train_size + val_size + test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equipped-latitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "useful-democrat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0b74861da597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n\u001b[0;32m---> 30\u001b[0;31m                   .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n\u001b[0m\u001b[1;32m     31\u001b[0m                           (correct / total) * 100))\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    print('-'*10)\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        # Back propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))\n",
    "        \n",
    "print(acc_list)\n",
    "#         inputs, labels = data\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         #print(loss)\n",
    "#         loss.backward()\n",
    "#         #print(loss)\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         #print(running_loss/20)\n",
    "#         if (i+1) % 20 == 0:    # print every 20 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 20))\n",
    "#             running_loss = 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     print(epoch)\n",
    "#     print('-'*10)\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "#         inputs, labels = data\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         #print(loss)\n",
    "#         loss.backward()\n",
    "#         #print(loss)\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         #print(running_loss/20)\n",
    "#         if (i+1) % 20 == 0:    # print every 20 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 20))\n",
    "#             running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "trying-shield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 379 test images: 22 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #print(labels)\n",
    "        outputs = net(images)\n",
    "        #print(outputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(_)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #print(correct)\n",
    "\n",
    "print(f'Accuracy of the network on the {test_size} test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "proof-lighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.size(): torch.Size([6, 3, 224, 224])\n",
      "loss.item(): 1.583852767944336\n",
      "running_loss: 0.0\n",
      "9.503116607666016\n",
      "train_loader.dataset:  <__main__.ImageDataset object at 0x7fd9f0312a60>\n",
      "Runnuing Loss:  0.0062561662986609715\n",
      "inputs.size(): torch.Size([6, 3, 224, 224])\n",
      "loss.item(): 1.7713686227798462\n",
      "running_loss: 0.0\n",
      "10.628211736679077\n",
      "train_loader.dataset:  <__main__.ImageDataset object at 0x7fd9f0312a60>\n",
      "Runnuing Loss:  0.006996847752915785\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        print('inputs.size():', inputs.size())\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('loss.item():', loss.item())\n",
    "        print('running_loss:', running_loss)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        print(running_loss)\n",
    "        break\n",
    "    print('train_loader.dataset: ', train_loader.dataset)\n",
    "    running_loss /= len(train_loader.dataset)\n",
    "    print('Runnuing Loss: ', running_loss)\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "            \n",
    "#print('Finish Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        print(labels.shape)\n",
    "        #print(inputs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/my_simple_net.pth'\n",
    "\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-details",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-doctrine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-hearing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('bolt', 'flange', 'lead_block', 'nut', 'pipe')\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print(' '.join('%5s' % classes[labels[j]] for j in range(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[56.0, 00.0, 4.4, 68.8],\n",
    "              [1.2, 104.0, 52.0, 8.0],\n",
    "              [1.8, 135.0, 99.0, 0.9]])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = A.sum(axis=0)\n",
    "print(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 100 * A/cal.reshape(1,4)\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[56.0, 00.0, 4.4, 68.8],\n",
    "              [1.2, 104.0, 52.0, 8.0],\n",
    "              [1.8, 135.0, 99.0, 0.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([56.0, 00.0, 4.4, 68.8, 58.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = B * C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "graphic-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func, train_loader, val_loader, epochs=20, device='cpu'):\n",
    "    for epoch in range(1,epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "    \n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data.item() * inputs.size(0) # TOCHECK (is the batch size and userd to get the loss of a\n",
    "                                                            # batch when batch size is not a factor of train_size)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        num_correct = 0.0\n",
    "        num_examples = 0.0\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(outputs, dim=1), dim=1)[1], labels)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        \n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, train_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "editorial-bracket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 1.79, Validation Loss: 1.79, accuracy = 0.21\n",
      "Epoch: 2, Training Loss: 1.79, Validation Loss: 1.79, accuracy = 0.21\n",
      "Epoch: 3, Training Loss: 1.79, Validation Loss: 1.79, accuracy = 0.21\n",
      "Epoch: 4, Training Loss: 1.79, Validation Loss: 1.79, accuracy = 0.21\n",
      "Epoch: 5, Training Loss: 1.79, Validation Loss: 1.79, accuracy = 0.21\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer,torch.nn.CrossEntropyLoss(), train_loader,val_loader, epochs=5, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stunning-norman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5, device='cuda:0')\n",
      "pipe\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "\n",
    "classes = ('bolt', 'flange', 'lead_block', 'nut', 'pipe', 'pipe')\n",
    "\n",
    "img = Image.open('../dataset/set_dataset/test/bolt_108.jpg')\n",
    "img = test_val_transforms(img).to(device)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "\n",
    "model.eval()\n",
    "prediction = F.softmax(model(img), dim=1)\n",
    "prediction = prediction.argmax()\n",
    "print(prediction)\n",
    "print(classes[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "direct-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4],\n",
    "                [5, 6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "drawn-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "greek-jason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]],\n",
       "\n",
       "        [[5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secure-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1613745848\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "name = f\"model_{int(time.time())}\"\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-timer",
   "metadata": {},
   "source": [
    "time.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "diverse-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = time.strftime(\"%d%m%Y-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "silver-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = f\"model_{date}{int(time.time())}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "speaking-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_19022021-1613746269.pth'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "improving-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = time.strftime(\"%d%m%Y-\")\n",
    "NAME = f\"model_{date}{int(time.time())}.pth\"\n",
    "PATH = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "legendary-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "full_path = os.path.join(PATH, NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tutorial-protection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/model_19022021-1613746410.pth'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-sustainability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 (torch-gpu)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
